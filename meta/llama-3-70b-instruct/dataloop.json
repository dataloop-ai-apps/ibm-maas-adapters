{
  "name": "ibm-api-llama-3-8b-instruct",
  "displayName": "Llama-3-8b-instruct IBM API",
  "version": "0.0.4",
  "scope": "public",
  "description": "Llama-3-8b-instruct from IBM API - Requires API Key and Project id",
  "attributes": {
    "Provider": "IBM",
    "Category": "Model",
    "Gen AI": "LLM",
    "NLP": "Conversational"
  },
  "codebase": {
    "type": "git",
    "gitUrl": "https://github.com/dataloop-ai-apps/ibm-maas-adapters.git",
    "gitTag": "0.0.4"
  },

  "components": {
    "computeConfigs": [
      {
        "name": "llama-3-8b-instruct-ibm-deploy",
        "runtime": {
          "podType": "regular-xs",
          "concurrency": 10,
          "runnerImage": "dataloopai/dtlpy-agent:cpu.py3.10.opencv",
          "autoscaler": {
            "type": "rabbitmq",
            "minReplicas": 0,
            "maxReplicas": 2
          }
        }
      }
    ],
    "modules": [
      {
        "name": "llama-3-8b-instruct-ibm-module",
        "entryPoint": "ibm_adapter.py",
        "className": "ModelAdapter",
        "computeConfig": "llama-3-8b-instruct-ibm-deploy",
        "description": "Llama-3-8b-instruct IBM API Adapter",
        "initInputs": [
          {
            "type": "Model",
            "name": "model_entity"
          },
          {
            "type": "String",
            "name": "ibm_api_key_name"
          }
        ],
        "functions": [
          {
            "name": "predict_items",
            "input": [
              {
                "type": "Item[]",
                "name": "items",
                "description": "List of items to run inference on"
              }
            ],
            "output": [
              {
                "type": "Item[]",
                "name": "items",
                "description": "The same input images for prediction."
              },
              {
                "type": "Annotation[]",
                "name": "annotations",
                "description": "The predicted annotations."
              }
            ],
            "displayName": "Predict Items",
            "displayIcon": "",
            "description": "IBM API Llama-3-8b-instruct predict items"
          },
          {
            "name": "predict_dataset",
            "input": [
              {
                "type": "Dataset",
                "name": "dataset",
                "description": ""
              },
              {
                "type": "Json",
                "name": "filters",
                "description": "Dataloop Filter DQL"
              }
            ],
            "output": [],
            "displayName": "Predict Dataset",
            "displayIcon": "",
            "description": "Function to run IBM API Llama-3-8b-instruct inference on a dataset"
          },
          {
            "name": "evaluate_model",
            "computeConfig": "deeplab-train-evaluate",
            "input": [
              {
                "type": "Model",
                "name": "model",
                "description": "Dataloop Model Entity"
              },
              {
                "type": "Dataset",
                "name": "dataset",
                "description": "Dataloop Dataset Entity"
              },
              {
                "type": "Json",
                "name": "filters",
                "description": "Dataloop Filter DQL"
              }
            ],
            "output": [
              {
                "type": "Model",
                "name": "model",
                "description": "Dataloop Model Entity"
              },
              {
                "type": "Dataset",
                "name": "dataset",
                "description": "Dataloop Dataset Entity"
              }
            ],
            "displayName": "Evaluate a Model",
            "displayIcon": "",
            "description": "Function to evaluate IBM API Llama-3-8b-instruct model performance"
          }
        ]
      }
    ],
    "models": [
      {
        "name": "llama-3-8b-instruct-ibm",
        "moduleName": "llama-3-8b-instruct-ibm-module",
        "scope": "project",
        "status": "pre-trained",
        "configuration": {
          "model_id": "meta-llama/llama-3-8b-instruct",
          "system_prompt": "You are a helpful and a bit cynical assistant. Give relevant and short answers, if you dont know the answer just say it, dont make up an answer",
          "min_new_tokens": 0,
          "max_new_tokens": 200,
          "stop_sequences": [],
          "project_id": "",
          "region": ""
        },
        "description": "The Llama-3-8b-instruct model supports summarization, classification, generation, extraction and translation tasks."
      }
    ]
  }
}
